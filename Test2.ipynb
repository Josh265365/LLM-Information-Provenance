{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f463a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Load the book's text\n",
    "with open('data/TKMBFullBook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "chapters = re.split(r'Chapter \\d+', text)\n",
    "if chapters[0].strip() == \"\":\n",
    "    chapters.pop(0) # Remove the empty string before the first chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c8cfe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 6318\n",
      "Example chunk: {'chapter': 3, 'chunk_id': '3_63', 'text': 'fault . “ Hush your fussin ‘ , ” she said . Jem and Walter returned to school ahead of me : staying behind to advise Atticus of Calpurnia ’ s iniquities was worth a solitary sprint past the Radley Place . “ She likes Jem better ’ n she likes me , anyway , ” I concluded , and suggested that Atticus lose no time in packing her off . “ Have you ever considered that Jem doesn ’'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "WINDOW = 80 # Number of tokens in each chunk\n",
    "STRIDE = 20 # Number of tokens to shift for the next chunk\n",
    "\n",
    "def chapter_to_chunks(chapter_text):\n",
    "    tokens = word_tokenize(chapter_text)\n",
    "    chunks = []\n",
    "    for start in range(0, len(tokens), STRIDE):\n",
    "        end = start + WINDOW\n",
    "        if end > len(tokens):\n",
    "            break\n",
    "        chunk_tokens = tokens[start:end]\n",
    "        chunks.append(\" \".join(chunk_tokens))\n",
    "    return chunks\n",
    "\n",
    "all_chunks = []\n",
    "for chap_num, chap_text in enumerate(chapters, start=1):\n",
    "    for i, chunk in enumerate(chapter_to_chunks(chap_text), start=1):\n",
    "        all_chunks.append({\n",
    "            \"chapter\": chap_num,\n",
    "            \"chunk_id\": f\"{chap_num}_{i}\",\n",
    "            \"text\": chunk\n",
    "        })\n",
    "print(f\"Total chunks created: {len(all_chunks)}\")\n",
    "print(f\"Example chunk: {all_chunks[500]}\")\n",
    "#print(chapters[0][:448])  # Print the first 500 characters of the first chapter for context\n",
    "#print(f\"Total chapters: {len(chapters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9dcc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Analyze the distribution of chunk lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5863bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text: str) -> list[str]:\n",
    "    \n",
    "      #normalizing curly apostrophes\n",
    "    text = text.replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
    "    # Removing multi-dots to a single space (...)\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "    # Replacing hyphens/slashes with spaces (so “cross-road” → “cross road”)\n",
    "    text = re.sub(r'[-/]', ' ', text)\n",
    "    # Removing all punctuation except apostrophes\n",
    "    # Keeping letters, numbers, whitespace, and apostrophes for contractions/possessives\n",
    "    text = re.sub(r\"[^\\w\\s']+\", '', text)\n",
    "    # Normalizing whitespace and lowercasing\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text.lower())  # Convert to lowercase for consistency\n",
    "    # Lemmatize each word\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Return the list of lemmatized tokens\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1653edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Create a list of lemmatized texts for BM25\n",
    "Corpus = [lemmatize_text(chunk['text']) for chunk in all_chunks]\n",
    "\n",
    "# Initialize BM25 with the corpus for ranking and retrieval\n",
    "bm25 = BM25Okapi(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "039de273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([231.32219414, 226.17348131, 221.04755136, ..., 211.13537439,\n",
       "       182.32492176, 188.50500111])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"The summer sun hung low over Maycomb, casting long shadows through the dusty streets and swaying branches of ancient oaks. Jem and Scout Finch sat on the porch steps, their bare feet dangling, watching the world with wide, curious eyes. It was the kind of afternoon where time seemed to slow, yet the air was thick with a tension they couldn’t quite name.\\nTommy Harris was new in town, a shy boy with a crooked smile who kept to himself. One afternoon, a window shattered at the church, and fingers quickly pointed toward Tommy. Rumors swirled — some said he was clumsy, others whispered darker things. But Jem and Scout, knowing the boy’s quiet kindness, couldn’t believe he was guilty of such mischief.\\nAtticus, their father, sat stiffly at the kitchen table, the weight of the town’s silent judgments pressing down on him. “Sometimes,” he said, “people see what they expect to see, not what is true.” His voice was calm, but Scout caught the flicker of sadness in his eyes.\\nThe trial was a schoolyard spectacle. Tommy, nervous and small against the towering accusations, tried to explain, but his innocence was swallowed by suspicion. The town’s fear painted him in shades of guilt, a stark contrast to the gentle boy Jem and Scout knew.\\nIn the end, it wasn’t the truth that won, but the loudest voices in the room. Jem and Scout learned that innocence, like a fragile flower, can be mistaken for something else entirely — a shadow cast longer by fear and misunderstanding. And in that small town, where the line between right and wrong blurred with the setting sun, the children held tight to the hope that one day, truth would find its way back to the light.\"\n",
    "processed_query = lemmatize_text(query)\n",
    "\n",
    "doc_scores = bm25.get_scores(processed_query)\n",
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09dfb9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found top 2 matching chunks:\n",
      "\n",
      "Rank 1:\n",
      "'chapter': 6, 'paragraph_Id': 6_29, 'bm25_score': 287.5896\n",
      "'text': then tried his weight by degrees . The step was silent . Jem skipped two steps , put his foot on the porch , heaved himself to it , and teetered a long moment . He regained his balance and dropped to his knees . He crawled to the window , raised his head and looked in . Then I saw the shadow . It was the shadow of a man with a hat on . At first I thought it was a tree , but there was no wind blowing , and tree-trunks never walked . The back porch was bathed in moonlight , and the shadow , crisp as toast , moved across the porch toward Jem . Dill saw it next . He put his hands to his face . When it crossed Jem , Jem saw it . He put his arms over his head and\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 2:\n",
      "'chapter': 26, 'paragraph_Id': 26_13, 'bm25_score': 281.4191\n",
      "'text': let us know he knew a lot more about something than we thought he knew . And it had happened years ago . No , only last summer—no , summer before last , when… time was playing tricks on me . I must remember to ask Jem . So many things had happened to us , Boo Radley was the least of our fears . Atticus said he didn ’ t see how anything else could happen , that things had a way of settling down , and after enough time passed people would forget that Tom Robinson ’ s existence was ever brought to their attention . Perhaps Atticus was right , but the events of the summer hung over us like smoke in a closed room . The adults in Maycomb never discussed the case with Jem and me ; it seemed that they discussed it with their\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "doc_scores = bm25.get_scores(processed_query)\n",
    "\n",
    "# Get the top 2 indices (not the token lists)\n",
    "top_indices = doc_scores.argsort()[-2:][::-1]  # Get indices of top 2 scores in descending order\n",
    "\n",
    "print(f\"Found top 2 matching chunks:\\n\")\n",
    "\n",
    "for rank, idx in enumerate(top_indices):\n",
    "    chunk = all_chunks[idx]\n",
    "    bm25_score = doc_scores[idx]\n",
    "    \n",
    "    print(f\"Rank {rank + 1}:\")\n",
    "    print(f\"'chapter': {chunk['chapter']}, 'paragraph_Id': {chunk['chunk_id']}, 'bm25_score': {bm25_score:.4f}\")\n",
    "    print(f\"'text': {chunk['text']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1edcb1",
   "metadata": {},
   "source": [
    "Evalute usinng precision @ K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21d829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee6e224",
   "metadata": {},
   "source": [
    "Addiotional Evalution and add some stats to the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
